# -*- coding: utf-8 -*-
"""sentiment_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NJii0V7SW6oUkh58bSI0SbUsy3v8DAbM
"""

from google.colab import drive
drive.mount('/content/drive')

import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import numpy as np
import re
import nltk
import pandas as pd
import nltk as nlp
nltk.download('stopwords')
import pickle
from nltk.corpus import stopwords
stopWords = set(stopwords.words('turkish'))
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')

df_train = pd.read_csv('/content/drive/MyDrive/train.csv', encoding='unicode_escape')
df_train.head()

df_test = pd.read_csv('/content/drive/MyDrive/test.csv', encoding= 'unicode_escape')
df_test.head()

def pre_processing(text):
    text = text.lower()
    text = re.sub("[^abcçdefgğhıijklmnoöprsştuüvyz]"," ",text)
    text=nltk.word_tokenize(text)
    text =[word for word in text if not word in set(stopwords.words("turkish"))]
    lemma=nlp.WordNetLemmatizer()
    text=[lemma.lemmatize(word) for word in text]
    text=" ".join(text)
    return text

df_train["clean_text"]=df_train["comment"].apply(lambda x: pre_processing(x))
df_test["clean_text"]=df_test["comment"].apply(lambda x: pre_processing(x))

df_train.head()

X_train=df_train["clean_text"]
X_test=df_test["clean_text"]
y_train=df_train["Label"]
y_test=df_test["Label"]

print("x_train",X_train.shape)
print("x_test",X_test.shape)
print("y_train",y_train.shape)
print("y_test",y_test.shape)

from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
LogisticRegression = Pipeline([('tfidf', TfidfVectorizer()),('clf', LogisticRegression())])

LogisticRegression .fit(X_train, y_train)

def plot_confusion_matrix(Y_test, Y_preds):
    conf_mat = confusion_matrix(Y_test, Y_preds)
    #print(conf_mat)
    fig = plt.figure(figsize=(6,6))
    plt.matshow(conf_mat, cmap=plt.cm.Blues, fignum=1)
    plt.yticks(range(2), range(2))
    plt.xticks(range(2), range(2))
    plt.colorbar();
    for i in range(2):
        for j in range(2):
            plt.text(i-0.2,j+0.1, str(conf_mat[j, i]), color='tab:red')

from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,precision_score
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import cross_val_score
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import classification_report

cv_scores = cross_val_score(LogisticRegression, X_train, y_train, cv=10)
print("CV average score: %.2f" % cv_scores.mean())

result = LogisticRegression.predict(X_test)
cr = classification_report(y_test, result)
print(cr)


print('Train Accuracy : %.3f'%LogisticRegression.score(X_train, y_train))
print('Test Accuracy : %.3f'%LogisticRegression.score(X_test, y_test))



y_pred = LogisticRegression.predict(X_test)
print(precision_score(y_test, y_pred ,average='macro') , ": is the precision score")
print(recall_score(y_test, y_pred,average='macro'), ": is the recall score")
print(f1_score(y_test, y_pred ,average='macro'), ": is the f1 score")

plot_confusion_matrix(y_test, LogisticRegression.predict(X_test))

!pip install requests
!pip install html5lib
!pip install bs4
!pip install selenium
!pip install pandas tabulate prettytable

import requests
from bs4 import BeautifulSoup

URL = "https://hdfilmcehennemi.cx/titanik-izle/"
r = requests.get(URL)

soup = BeautifulSoup(r.content, 'html.parser')

# Yorumların bulunduğu div etiketlerini bulma
comment_divs = soup.find_all("div", {"class": "comment-body"})

# Yorum metinlerini çekme
comment_list = []
for comment_div in comment_divs:
    p_tag = comment_div.find("p")
    if p_tag:
        comment_list.append(p_tag.text.strip())

# Yorumları yazdırma
if comment_list:
    for idx, comment in enumerate(comment_list):
        print(f"Comment {idx+1}: {comment}")
else:
    print("No comments found")

# Belirli bir yorumu yazdırma
try:
    print(comment_list[3])
except IndexError:
    print("There are less than 4 comments")

def analyze_comments(comments, pipeline):
    positive_comments = []
    negative_comments = []

    for comment in comments:
        prediction = pipeline.predict([comment])
        proportion = pipeline.predict_proba([comment])

        if prediction[0] == 1:
            positive_comments.append((comment, proportion[0][1]))
        else:
            negative_comments.append((comment, proportion[0][0]))

    return positive_comments, negative_comments

positive_comments, negative_comments = analyze_comments(comment_list, LogisticRegression)

from prettytable import PrettyTable

table = PrettyTable()

table.field_names = ["Comment", "Sentiment Probability", "Sentiment"]

for comment, sentiment_prob in positive_comments:
    if len(comment) > 50:
        comment = comment[:50] + "..."
    table.add_row([comment, f"{sentiment_prob:.2f}", "Positive"])

for comment, sentiment_prob in negative_comments:
    if len(comment) > 50:
        comment = comment[:50] + "..."
    table.add_row([comment, f"{sentiment_prob:.2f}", "Negative"])


print(table)

import pandas as pd
import matplotlib.pyplot as plt

def analyze_comments(comments, pipeline):
    positive_comments = []
    negative_comments = []

    for comment in comments:
        prediction = pipeline.predict([comment])
        proportion = pipeline.predict_proba([comment])

        if prediction[0] == 1:
            positive_comments.append((comment, proportion[0][1]))
        else:
            negative_comments.append((comment, proportion[0][0]))

    return positive_comments, negative_comments

positive_comments, negative_comments = analyze_comments(comment_list, LogisticRegression)

num_positive = len(positive_comments)
num_negative = len(negative_comments)

data = {'Sentiment': ['Positive', 'Negative'],
        'Count': [num_positive, num_negative]}
df = pd.DataFrame(data)

print("Yorum Sentimentlerinin Sayısı:")
print(df)

# Dağılımı gösteren çubuk grafiği ve pasta grafiği
plt.figure(figsize=(12, 6))

# Çubuk grafiği
plt.subplot(1, 2, 1)
plt.bar(df['Sentiment'], df['Count'], color=['purple', 'gray'])
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.title('Sentiment Distribution of Comments (Bar)')

# Pasta grafiği
plt.subplot(1, 2, 2)
plt.pie(df['Count'], labels=df['Sentiment'], autopct='%1.1f%%', colors=['blue', 'orange'])
plt.title('Sentiment Distribution of Comments (Pie)')

plt.tight_layout()
plt.show()

comment_list = ["comment1", "comment2", "comment3", "comment4", "comment5"]

predictions = [0, 1, 1, 0, 1]

y_test = [0, 1, 0, 0, 1]


correct_predictions = 0
total_predictions = len(comment_list)

for i in range(total_predictions):

    if predictions[i] == y_test[i]:
        correct_predictions += 1

accuracy = (correct_predictions / total_predictions) * 100
print("Başarı Yüzdesi: {:.2f}%".format(accuracy))